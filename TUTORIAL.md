# üìö Tutorial: Sistema de Detec√ß√£o de Buracos

## üìñ √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Estrutura do Projeto](#estrutura-do-projeto)
3. [M√≥dulos Detalhados](#m√≥dulos-detalhados)
4. [Fluxo de Execu√ß√£o](#fluxo-de-execu√ß√£o)
5. [Vari√°veis Importantes](#vari√°veis-importantes)

---

## üéØ Vis√£o Geral

Este sistema detecta buracos em tempo real usando:
- **C√¢mera Raspberry Pi** para captura de imagens
- **YOLO (Ultralytics)** para detec√ß√£o de objetos
- **LIDAR** para medir dist√¢ncias
- **Flask** para interface web
- **SQLite** para armazenar detec√ß√µes

### Como funciona?
1. A c√¢mera captura frames continuamente
2. O YOLO analisa cada frame em busca de buracos
3. O LIDAR fornece a dist√¢ncia dos objetos detectados
4. Os dados s√£o salvos no banco SQLite
5. A interface web mostra tudo em tempo real

---

## üìÅ Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ main.py            # üöÄ Arquivo principal - inicia tudo
‚îú‚îÄ‚îÄ database.py        # üíæ Gerencia o banco de dados SQLite
‚îú‚îÄ‚îÄ camera.py          # üì∑ Captura frames da c√¢mera
‚îú‚îÄ‚îÄ detector.py        # üîç Detecta buracos com YOLO
‚îú‚îÄ‚îÄ lidar_manager.py   # üì° L√™ dados do sensor LIDAR
‚îú‚îÄ‚îÄ api.py             # üåê Rotas da API Flask
‚îú‚îÄ‚îÄ utils.py           # üõ†Ô∏è Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ opencv_analyzer.py # üé® An√°lise geom√©trica com OpenCV (FASE 1)
‚îú‚îÄ‚îÄ tracker.py         # üéØ Rastreamento de buracos (FASE 1)
‚îú‚îÄ‚îÄ mapper.py          # üó∫Ô∏è Construtor de mapas 2D (FASE 2)
‚îú‚îÄ‚îÄ map_utils.py       # üß≠ Convers√µes de coordenadas (FASE 2)
‚îú‚îÄ‚îÄ calibration.py       # üìê Calibra√ß√£o de c√¢mera (FASE 3)
‚îú‚îÄ‚îÄ depth_estimator.py   # üî¨ Estimativa de profundidade (FASE 3)
‚îú‚îÄ‚îÄ texture_analyzer.py  # üé® An√°lise avan√ßada de textura (FASE 4)
‚îú‚îÄ‚îÄ damage_classifier.py # üîç Classifica√ß√£o de tipo de dano (FASE 4)
‚îú‚îÄ‚îÄ roi_detector.py      # ‚ö° Detec√ß√£o de ROI (FASE 5)
‚îú‚îÄ‚îÄ motion_detector.py   # ‚ö° Detec√ß√£o de movimento (FASE 5)
‚îî‚îÄ‚îÄ performance_optimizer.py # ‚ö° Multi-threading e otimiza√ß√£o (FASE 5)
```

---

## üì¶ M√≥dulos Detalhados

### 1. `main.py` - Arquivo Principal

**O que faz:** Inicializa e coordena todos os componentes do sistema.

```python
def main():
    """Fun√ß√£o principal de inicializa√ß√£o"""
```

#### Passo a Passo:

**1. Cria diret√≥rio para salvar fotos**
```python
screenshot_dir = '/home/suple/Desktop/suple360v2/deteccoes'
os.makedirs(screenshot_dir, exist_ok=True)
```
- `screenshot_dir`: caminho onde as fotos ser√£o salvas
- `exist_ok=True`: n√£o d√° erro se a pasta j√° existir

**2. Inicializa o Banco de Dados**
```python
db_manager = DatabaseManager()
```
- `db_manager`: objeto que gerencia todas as opera√ß√µes do banco
- Cria as tabelas automaticamente se n√£o existirem

**3. Inicializa o LIDAR**
```python
lidar_manager = LidarManager(
    port="/dev/ttyUSB0",     # Porta USB onde o LIDAR est√° conectado
    baud=115200,             # Velocidade de comunica√ß√£o (bits por segundo)
    sector_deg=5             # Agrupa leituras a cada 5 graus
)
lidar_manager.start()
```

**4. Carrega o Modelo YOLO**
```python
model = YOLO('/home/suple/Desktop/suple360v2/model/best.pt')
```
- `best.pt`: arquivo do modelo treinado para detectar buracos

**5. Inicializa a C√¢mera**
```python
camera = picamera2.Picamera2()
config = camera.create_preview_configuration(main={"size": (1280, 720)})
```
- Resolu√ß√£o: 1280x720 pixels (HD)
- Balanceia qualidade e velocidade de processamento

**6. Inicia Gerenciador da C√¢mera**
```python
camera_manager = CameraManager(camera)
camera_manager.start()
```
- Captura frames em uma thread separada
- Mant√©m o stream fluido

**7. Inicia o Detector**
```python
detector = Detector(
    model=model,                    # Modelo YOLO
    db_manager=db_manager,          # Banco de dados
    lidar_manager=lidar_manager,    # Sensor LIDAR
    camera_manager=camera_manager,  # C√¢mera
    screenshot_dir=screenshot_dir,  # Onde salvar fotos
    cam_hfov_deg=70.0              # Campo de vis√£o horizontal (70¬∞)
)
detector.start()
```

**8. Inicia Servidor Web**
```python
app = create_app(db_manager, camera_manager, lidar_manager)
flask_thread = threading.Thread(target=run_flask, daemon=True)
flask_thread.start()
```
- `daemon=True`: a thread fecha quando o programa principal fechar
- Roda na porta 5000

---

### 2. `database.py` - Gerenciamento de Dados

**O que faz:** Armazena e recupera detec√ß√µes do banco SQLite.

#### Classe `DatabaseManager`

**Vari√°veis de Inst√¢ncia:**
```python
self.db_path = "deteccoes/detections.db"  # Caminho do arquivo do banco
self.lock = threading.Lock()               # Previne conflitos entre threads
```

#### Tabelas do Banco:

**1. Tabela `detections`** (Detec√ß√µes principais)
```sql
id              # Identificador √∫nico (auto-incremento)
timestamp       # Data/hora da detec√ß√£o ("2026-01-05 20:08:33")
photo_path      # Nome do arquivo da foto ("buraco_20260105_200833_1.jpg")
num_buracos     # Quantidade de buracos detectados
created_at      # Quando o registro foi criado
```

**2. Tabela `buracos`** (Detalhes de cada buraco)
```sql
id              # Identificador √∫nico
detection_id    # Liga ao registro da tabela detections
bbox_x1, y1     # Canto superior esquerdo do ret√¢ngulo
bbox_x2, y2     # Canto inferior direito do ret√¢ngulo
confianca       # Confian√ßa da detec√ß√£o (0.0 a 1.0)
distancia_m     # Dist√¢ncia em metros (do LIDAR)
largura_m       # Largura estimada em metros
```

#### M√©todos Principais:

**`add_detection(photo_path, boxes, timestamp)`**
- Salva uma nova detec√ß√£o no banco
- `photo_path`: nome da foto (ex: "buraco_20260105_200833_1.jpg")
- `boxes`: lista de buracos detectados
- `timestamp`: momento da detec√ß√£o

**`get_recent(limit=20)`**
- Retorna as √∫ltimas detec√ß√µes
- `limit`: quantas detec√ß√µes retornar (padr√£o: 20)

**`get_stats()`**
- Retorna estat√≠sticas gerais:
  - Total de detec√ß√µes
  - Total de buracos

---

### 3. `camera.py` - Captura de Imagens

**O que faz:** Captura frames da c√¢mera continuamente e aplica overlays visuais.

#### Classe `CameraManager`

**Vari√°veis de Inst√¢ncia:**
```python
self.camera           # Objeto da c√¢mera Picamera2
self.frame_global     # Frame com desenhos (enviado para a web)
self.latest_frame     # Frame original mais recente
self.detection_boxes  # Lista de caixas delimitadoras atuais
self.detection_text   # Texto de status ("Buraco detectado!")
self.detection_color  # Cor do texto (verde ou vermelho)
self.lock            # Previne conflitos entre threads
self.frame_count     # Contador de frames capturados
```

#### M√©todos Principais:

**`get_latest_frame()`**
- Retorna uma c√≥pia do √∫ltimo frame capturado
- Usado pelo detector para an√°lise

**`update_detections(boxes, text, color)`**
- Atualiza as informa√ß√µes de detec√ß√£o para desenhar
- `boxes`: lista com coordenadas dos buracos
- `text`: mensagem de status
- `color`: cor (verde = OK, vermelho = buraco detectado)

**`capture_loop()`** - Loop principal de captura
```python
while True:
    frame = self.camera.capture_array()  # Captura frame
    
    # Converte formato de cor
    if frame.shape[2] == 4:
        frame = frame[:, :, :3]          # Remove canal alpha
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    self.frame_count += 1                # Incrementa contador
    
    # Desenha overlays (boxes, texto)
    frame_vis = draw_overlays(frame.copy(), boxes, text, color, frame_id)
    
    self.frame_global = frame_vis        # Atualiza frame para stream
```

---

### 4. `detector.py` - Detec√ß√£o de Buracos

**O que faz:** Usa YOLO para detectar buracos e funde com dados do LIDAR.

#### Classe `Detector`

**Vari√°veis de Inst√¢ncia:**
```python
self.model              # Modelo YOLO treinado
self.db_manager         # Gerenciador do banco de dados
self.lidar_manager      # Gerenciador do LIDAR
self.camera_manager     # Gerenciador da c√¢mera
self.screenshot_dir     # Pasta para salvar fotos
self.cam_hfov_deg       # Campo de vis√£o horizontal (70¬∞)
self.detection_counter  # Contador de detec√ß√µes
```

#### M√©todo Principal: `detection_loop()`

**Passo 1: Redimensiona frame para detec√ß√£o**
```python
target_w, target_h = 640, 360
det_input = cv2.resize(frame, (target_w, target_h))
results = self.model(det_input)
```
- Reduz resolu√ß√£o para processar mais r√°pido
- 640x360 √© suficiente para detec√ß√£o precisa

**Passo 2: Processa cada detec√ß√£o**
```python
for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = box.xyxy[0]  # Coordenadas do ret√¢ngulo
        conf = box.conf[0]             # Confian√ßa (0.0 a 1.0)
```

**Passo 3: Calcula √¢ngulo e dist√¢ncia**
```python
x_center = (x1 + x2) / 2.0           # Centro do buraco
rel = (x_center / frame_w) - 0.5     # Posi√ß√£o relativa (-0.5 a 0.5)
angle_deg = rel * self.cam_hfov_deg  # Converte para √¢ngulo

dist_m = self.lidar_manager.sector_to_distance(angle_deg)
```
- Se o buraco est√° no centro: `angle_deg = 0¬∞`
- Se est√° na esquerda: `angle_deg` negativo
- Se est√° na direita: `angle_deg` positivo

**Passo 4: Estima largura do buraco**
```python
if dist_m is not None:
    box_ang = ((x2 - x1) / frame_w) * self.cam_hfov_deg
    width_m = dist_m * 2 * 3.14159 * (box_ang / 360.0)
```
- Usa geometria: largura = dist√¢ncia √ó √¢ngulo
- Quanto mais longe, maior a largura real

**Passo 5: Salva detec√ß√£o**
```python
if new_boxes:
    filename = f"buraco_{time.strftime('%Y%m%d_%H%M%S')}_{counter}.jpg"
    cv2.imwrite(full_path, annotated)
    
    self.db_manager.add_detection(
        photo_path=filename,
        boxes=new_boxes,
        timestamp=timestamp
    )
```

---

### 5. `lidar_manager.py` - Sensor de Dist√¢ncia

**O que faz:** L√™ dados do sensor LIDAR e os organiza por setores angulares.

#### Classe `LidarManager`

**Vari√°veis de Inst√¢ncia:**
```python
self.port = "/dev/ttyUSB0"    # Porta USB do LIDAR
self.baud = 115200            # Taxa de comunica√ß√£o
self.sector_deg = 5           # Tamanho de cada setor (5¬∞)
self.data = {}                # Dicion√°rio: {√¢ngulo: dist√¢ncia}
self.lock = threading.Lock()  # Sincroniza√ß√£o entre threads
```

#### Como funciona o LIDAR?

**1. Leitura em 360 graus**
```
  0¬∞ (frente)
   |
   |
270¬∞--+--90¬∞
   |
   |
  180¬∞ (tr√°s)
```

**2. Agrega√ß√£o por setores**
```python
sector = int(round(angle / self.sector_deg) * self.sector_deg) % 360
```
- √Çngulos 0-4¬∞ ‚Üí Setor 0¬∞
- √Çngulos 5-9¬∞ ‚Üí Setor 5¬∞
- √Çngulos 10-14¬∞ ‚Üí Setor 10¬∞
- E assim por diante...

**3. Guarda menor dist√¢ncia**
```python
agg[sector] = min(agg.get(sector, distance), distance)
```
- Se houver m√∫ltiplas leituras no mesmo setor, guarda a menor
- Isso detecta o objeto mais pr√≥ximo

#### M√©todo `sector_to_distance(angle_deg)`
```python
def sector_to_distance(self, angle_deg):
    angle_norm = angle_deg % 360              # Normaliza: -10¬∞ vira 350¬∞
    sector = int(round(angle_norm / 5) * 5)   # Arredonda para setor
    return self.data.get(sector)              # Retorna dist√¢ncia
```

**Exemplo:**
- Buraco detectado a `angle_deg = 12¬∞`
- Setor mais pr√≥ximo: `10¬∞`
- Retorna a dist√¢ncia armazenada para o setor 10¬∞

---

### 6. `api.py` - Interface Web

**O que faz:** Cria rotas HTTP para acessar o sistema via navegador.

#### Principais Rotas:

**`/` - P√°gina inicial**
```python
@app.route('/')
def index():
    return render_template('index.html')
```

**`/video_feed` - Stream de v√≠deo**
```python
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), 
                   mimetype='multipart/x-mixed-replace; boundary=frame')
```
- Envia frames continuamente (MJPEG)
- Atualiza a imagem no navegador em tempo real

**`/api/detections/recent` - √öltimas detec√ß√µes**
```python
@app.route('/api/detections/recent')
def get_recent_detections():
    detections = db_manager.get_recent(limit=20)
    return jsonify({"detections": detections})
```
- Retorna JSON com as √∫ltimas 20 detec√ß√µes

**`/api/lidar/latest` - Dados do LIDAR**
```python
@app.route('/api/lidar/latest')
def lidar_latest():
    data = lidar_manager.get_data()
    return jsonify({
        "sectors": data,
        "sector_deg": 5,
        "available": True
    })
```

**`/deteccoes/<filename>` - Servir imagens**
```python
@app.route('/deteccoes/<path:filename>')
def serve_detection_image(filename):
    filepath = os.path.join(deteccoes_dir, filename)
    return send_file(filepath, mimetype='image/jpeg')
```

---

### 7. `utils.py` - Fun√ß√µes Auxiliares

**O que faz:** Fun√ß√µes para desenhar overlays nos frames.

#### Fun√ß√£o `draw_overlays(frame, boxes, text, color, frame_id)`

**Par√¢metros:**
- `frame`: imagem onde desenhar
- `boxes`: lista de ret√¢ngulos [(x1,y1,x2,y2,conf,dist,width), ...]
- `text`: texto de status
- `color`: cor do texto (tupla RGB)
- `frame_id`: n√∫mero do frame (opcional)

**O que desenha:**

**1. N√∫mero do frame**
```python
cv2.putText(frame, f"Frame {frame_id}", (10, 30), ...)
```
- Posi√ß√£o: canto superior esquerdo (10, 30)

**2. Ret√¢ngulos ao redor de buracos**
```python
cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
```
- Cor verde: (0, 255, 0)
- Espessura: 2 pixels

**3. Labels com informa√ß√µes**
```python
label = f"Buraco {conf:.2f} | {dist_m:.1f}m | L~{width_m:.2f}m"
cv2.putText(frame, label, (x1, y1 - 10), ...)
```
- Exemplo: "Buraco 0.95 | 2.3m | L~0.45m"
- Posi√ß√£o: acima do ret√¢ngulo

**4. Texto de status**
```python
cv2.putText(frame, text, (10, 70), ...)
```
- Exemplo: "‚úì BURACO DETECTADO! (2 objeto(s))"

---

### 8. `opencv_analyzer.py` - An√°lise Geom√©trica (FASE 1) üÜï

**O que faz:** Analisa profundamente cada buraco usando t√©cnicas avan√ßadas de OpenCV.

#### Classe `OpenCVAnalyzer`

**M√©todo Principal: `analisar_buraco(frame, bbox, distancia_m)`**

**Entrada:**
- `frame`: Imagem completa da c√¢mera
- `bbox`: Coordenadas do buraco `(x1, y1, x2, y2)`
- `distancia_m`: Dist√¢ncia do LIDAR (opcional)

**Sa√≠da:** Dicion√°rio completo com:

**1. Dimens√µes em Pixels**
```python
{
    'largura_px': 203,      # Largura em pixels
    'altura_px': 89,        # Altura em pixels
    'area_px': 14250,       # √Årea total
    'perimetro_px': 584     # Per√≠metro
}
```

**2. Dimens√µes Reais (em metros)**
```python
{
    'largura_m': 0.452,     # Largura real
    'altura_m': 0.321,      # Altura real
    'area_m2': 0.1145,      # √Årea em m¬≤
    'perimetro_m': 1.423    # Per√≠metro em metros
}
```

**3. Geometria**
```python
{
    'aspect_ratio': 1.18,         # Propor√ß√£o largura/altura
    'circularidade': 0.82,        # 0=irregular, 1=c√≠rculo perfeito
    'convexidade': 0.91,          # 0=muito irregular, 1=convexo
    'orientacao_deg': 23.4,       # √Çngulo de rota√ß√£o
    'elipse_eixo_maior': 0.50,    # Eixo maior da elipse ajustada
    'elipse_eixo_menor': 0.35     # Eixo menor
}
```

**4. Textura**
```python
{
    'intensidade_media': 87.3,    # Brilho m√©dio (0-255)
    'desvio_padrao': 24.1,        # Varia√ß√£o de brilho
    'contraste': 0.68             # Contraste (0-1)
}
```

**5. Classifica√ß√£o Autom√°tica**
```python
{
    'severidade': 'media',         # leve / media / grave
    'necessita_reparo': True,      # Precisa consertar?
    'prioridade': 'media'          # baixa / media / alta
}
```

#### Como Funciona Internamente?

**Passo 1: Extra√ß√£o de Contorno**
```python
def _extrair_contorno(gray_image):
    # Binariza√ß√£o adaptativa (se adapta √† ilumina√ß√£o)
    thresh = cv2.adaptiveThreshold(...)
    
    # Encontra contornos (bordas do buraco)
    contours = cv2.findContours(thresh, ...)
    
    # Retorna o maior contorno
    return max(contours, key=cv2.contourArea)
```

**Passo 2: An√°lise Geom√©trica**
```python
def _analisar_geometria(contorno):
    # √Årea do contorno
    area = cv2.contourArea(contorno)
    
    # Per√≠metro do contorno
    perimetro = cv2.arcLength(contorno, True)
    
    # Circularidade: 4œÄ √ó √°rea / per√≠metro¬≤
    # C√≠rculo perfeito = 1.0
    circularidade = (4 * œÄ * area) / (perimetro¬≤)
    
    # Convex Hull (envolt√≥ria convexa)
    hull = cv2.convexHull(contorno)
    convexidade = area / area_hull
    
    # Elipse ajustada
    ellipse = cv2.fitEllipse(contorno)
    # Retorna orienta√ß√£o e eixos
```

**Passo 3: Convers√£o Pixel ‚Üí Metro**
```python
def _converter_para_metros(geometria, distancia_m):
    # Calcula largura real do campo de vis√£o
    largura_real_m = 2 √ó distancia √ó tan(FOV/2)
    
    # Fator de convers√£o
    metros_por_pixel = largura_real_m / largura_px
    
    # Converte todas as medidas
    area_m2 = area_px √ó (metros_por_pixel)¬≤
```

**Passo 4: Classifica√ß√£o de Severidade**
```python
def _classificar_severidade(area_m2, circularidade):
    if area_m2 < 0.05 and circularidade > 0.7:
        return 'leve'  # Buraco pequeno e circular
    elif area_m2 > 0.15 or circularidade < 0.4:
        return 'grave'  # Grande ou muito irregular
    else:
        return 'media'
```

---

### 9. `tracker.py` - Rastreamento de Buracos (FASE 1) üÜï

**O que faz:** Rastreia buracos entre frames consecutivos para evitar salvar o mesmo buraco m√∫ltiplas vezes.

#### Problema que Resolve:

**Antes (sem tracker):**
```
Frame 1: Detecta buraco ‚Üí Salva no banco (ID 1)
Frame 2: Detecta MESMO buraco ‚Üí Salva de novo (ID 2) ‚ùå
Frame 3: Detecta MESMO buraco ‚Üí Salva de novo (ID 3) ‚ùå
...
Resultado: 1 buraco = 30 registros! üò±
```

**Depois (com tracker):**
```
Frame 1: Detecta buraco ‚Üí NOVO! Salva (Track ID 1) ‚úÖ
Frame 2: Detecta buraco ‚Üí MESMO! N√£o salva ‚úÖ
Frame 3: Detecta buraco ‚Üí MESMO! N√£o salva ‚úÖ
...
Resultado: 1 buraco = 1 registro! üéâ
```

#### Classe `BuracoTracker`

**Vari√°veis de Inst√¢ncia:**
```python
self.tracked_buracos = []      # Lista de buracos rastreados
self.iou_threshold = 0.3       # Limiar para considerar "mesmo buraco"
self.max_age_seconds = 5.0     # Tempo para esquecer buraco antigo
self.next_id = 1               # Pr√≥ximo ID de track
```

**M√©todo Principal: `update(detections)`**

**Entrada:**
```python
detections = [
    (x1, y1, x2, y2, conf, dist_m, width_m),
    (x1, y1, x2, y2, conf, dist_m, width_m),
    ...
]
```

**Sa√≠da:**
```python
(novos_buracos, buracos_atualizados)

novos_buracos = [
    {'track_id': 1, 'detection': (...), 'is_new': True},
    ...
]

buracos_atualizados = [
    {'track_id': 2, 'detection': (...), 'is_new': False, 'count': 5},
    ...
]
```

#### Algoritmo de Matching (IoU)

**IoU = Intersection over Union**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Bbox 1  ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    ‚îÇ IoU‚îÇ    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
     ‚îÇ Bbox 2  ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

IoU = √Årea de Interse√ß√£o / √Årea de Uni√£o
```

**C√°lculo de IoU:**
```python
def _calculate_iou(bbox1, bbox2):
    # Coordenadas da interse√ß√£o
    x1_i = max(x1_bbox1, x1_bbox2)
    y1_i = max(y1_bbox1, y1_bbox2)
    x2_i = min(x2_bbox1, x2_bbox2)
    y2_i = min(y2_bbox1, y2_bbox2)
    
    # √Årea de interse√ß√£o
    if x2_i < x1_i or y2_i < y1_i:
        intersection = 0
    else:
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
    
    # √Årea de uni√£o
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    return intersection / union
```

**Interpreta√ß√£o do IoU:**
- `IoU = 0.0` ‚Üí Boxes n√£o se tocam
- `IoU = 0.3` ‚Üí Overlap pequeno (threshold padr√£o)
- `IoU = 0.5` ‚Üí Overlap m√©dio
- `IoU = 1.0` ‚Üí Boxes id√™nticos

#### L√≥gica de Tracking:

```python
for cada_nova_detec√ß√£o:
    melhor_match = None
    melhor_iou = 0
    
    for cada_track_existente:
        iou = calcular_iou(nova_detec√ß√£o, track)
        
        if iou > threshold AND iou > melhor_iou:
            melhor_match = track
            melhor_iou = iou
    
    if melhor_match encontrado:
        # √â o MESMO buraco!
        atualizar_track(melhor_match)
        adicionar_em_buracos_atualizados()
    else:
        # √â um NOVO buraco!
        criar_novo_track()
        adicionar_em_novos_buracos()
```

#### Suaviza√ß√£o de Posi√ß√£o

Quando um buraco √© re-detectado, a posi√ß√£o √© suavizada:

```python
def _smooth_bbox(old_bbox, new_bbox, alpha=0.7):
    # M√©dia ponderada
    smoothed_x1 = 0.7 √ó new_x1 + 0.3 √ó old_x1
    smoothed_y1 = 0.7 √ó new_y1 + 0.3 √ó old_y1
    # ... (para todos os pontos)
    
    return smoothed_bbox
```

Isso evita "tremidas" na posi√ß√£o do box.

#### Limpeza Autom√°tica

Buracos que saem do campo de vis√£o s√£o removidos:

```python
def _remove_old_tracks(current_time):
    # Remove tracks n√£o vistos h√° mais de 5 segundos
    self.tracked_buracos = [
        track for track in self.tracked_buracos
        if current_time - track['last_seen'] <= 5.0
    ]
```

---

## üîÑ Fluxo de Execu√ß√£o

### Inicializa√ß√£o (main.py)
```
1. Cria pastas necess√°rias
2. Inicializa banco de dados
3. Inicia LIDAR em background
4. Carrega modelo YOLO
5. Inicia c√¢mera
6. Inicia gerenciador de c√¢mera
7. Inicia detector
8. Inicia servidor web Flask
```

### Durante a Execu√ß√£o

**Thread 1: Captura de C√¢mera** (camera.py)
```
Loop infinito:
  1. Captura frame da c√¢mera
  2. Converte formato de cor
  3. Pega informa√ß√µes de detec√ß√£o atuais
  4. Desenha overlays (boxes, texto)
  5. Atualiza frame_global para stream
  6. Repete (~30 FPS)
```

**Thread 2: Detec√ß√£o YOLO + An√°lise OpenCV + Tracking** (detector.py) üÜï
```
Loop infinito:
  1. Pega √∫ltimo frame capturado
  2. Redimensiona para 640x360
  3. Roda YOLO para detectar buracos
  4. Para cada buraco encontrado:
     - Calcula √¢ngulo em rela√ß√£o √† c√¢mera
     - Busca dist√¢ncia no LIDAR
     - Estima largura do buraco
  5. Atualiza Tracker com detec√ß√µes:
     - Compara com buracos j√° rastreados (IoU)
     - Identifica NOVOS vs ATUALIZADOS
  6. Para cada NOVO buraco:
     ‚ú® An√°lise OpenCV Completa:
     - Extrai contorno preciso
     - Calcula √°rea, per√≠metro, circularidade
     - Converte pixels ‚Üí metros
     - Analisa textura
     - Classifica severidade
     - Salva foto com anota√ß√µes
     - Registra no banco com TODOS os dados
  7. Para buracos ATUALIZADOS:
     - Apenas atualiza display (n√£o salva de novo)
  8. Atualiza estado para c√¢mera desenhar
  9. Repete
```

**Diferen√ßa da Fase 1:**
- ‚úÖ Tracker evita duplicatas no banco
- ‚úÖ OpenCV extrai 20+ m√©tricas por buraco
- ‚úÖ Classifica√ß√£o autom√°tica de severidade
- ‚úÖ Log detalhado no console

**Thread 3: Leitura LIDAR** (lidar_manager.py)
```
Loop infinito:
  1. Conecta ao LIDAR
  2. Para cada varredura 360¬∞:
     - Agrupa leituras por setor de 5¬∞
     - Guarda menor dist√¢ncia de cada setor
     - Atualiza dicion√°rio de dados
  3. Se desconectar, tenta reconectar
  4. Repete continuamente
```

**Thread 4: Servidor Web** (api.py)
```
Aguarda requisi√ß√µes HTTP:
  - GET / ‚Üí P√°gina inicial
  - GET /video_feed ‚Üí Stream de v√≠deo
  - GET /api/detections/recent ‚Üí √öltimas detec√ß√µes
  - GET /api/lidar/latest ‚Üí Dados do LIDAR
  - GET /deteccoes/<foto> ‚Üí Imagem espec√≠fica
```

---

## üìä Vari√°veis Importantes

### Configura√ß√µes Gerais
```python
screenshot_dir = '/home/suple/Desktop/suple360v2/deteccoes'  # Pasta de fotos
db_path = 'deteccoes/detections.db'                          # Arquivo do banco
```

### C√¢mera
```python
camera_resolution = (1280, 720)     # Resolu√ß√£o HD
detection_resolution = (640, 360)   # Resolu√ß√£o para YOLO (mais r√°pido)
cam_hfov_deg = 70.0                 # Campo de vis√£o horizontal
```

### LIDAR
```python
LIDAR_PORT = "/dev/ttyUSB0"    # Porta USB
LIDAR_BAUD = 115200            # Taxa de comunica√ß√£o
LIDAR_SECTOR_DEG = 5           # Tamanho de cada setor angular
```

### Servidor Web
```python
FLASK_HOST = '0.0.0.0'         # Aceita conex√µes de qualquer IP
FLASK_PORT = 5000              # Porta HTTP
```

### Modelo YOLO
```python
model_path = '/home/suple/Desktop/suple360v2/model/best.pt'
```

### Detec√ß√£o
```python
detection_boxes = [
    (x1, y1, x2, y2, conf, dist_m, width_m),
    ...
]
```
Onde:
- `x1, y1`: canto superior esquerdo
- `x2, y2`: canto inferior direito
- `conf`: confian√ßa (0.0 a 1.0)
- `dist_m`: dist√¢ncia em metros
- `width_m`: largura estimada em metros

---

## üéì Conceitos Importantes

### Threading (Multithreading)
- Permite executar v√°rias tarefas simultaneamente
- Cada `Thread` roda um loop independente
- `daemon=True`: thread morre com o programa principal
- `lock`: previne conflitos ao acessar vari√°veis compartilhadas

### Lock (Sincroniza√ß√£o)
```python
with lock:
    # C√≥digo protegido
    # Apenas uma thread pode executar por vez
```

### Coordenadas de Imagem
```
(0,0) -------- x (largura) -----‚Üí
  |
  |
  y (altura)
  |
  ‚Üì
```
- Origem (0,0) no canto superior esquerdo
- X cresce para a direita
- Y cresce para baixo

### Bounding Box (Caixa Delimitadora)
```
(x1, y1) ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ         ‚îÇ
         ‚îÇ BURACO  ‚îÇ
         ‚îÇ         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (x2, y2)
```

### Convers√£o de √Çngulos
```python
# Posi√ß√£o no frame ‚Üí √Çngulo relativo √† c√¢mera
x_center = (x1 + x2) / 2.0           # Centro do objeto
rel = (x_center / frame_width) - 0.5 # -0.5 (esquerda) a 0.5 (direita)
angle_deg = rel * cam_hfov_deg       # √Çngulo em graus
```

**Exemplo:**
- Frame: 1280 pixels de largura
- C√¢mera: 70¬∞ de campo de vis√£o
- Buraco no centro (x=640): `angle = 0¬∞`
- Buraco na direita (x=1280): `angle = 35¬∞`
- Buraco na esquerda (x=0): `angle = -35¬∞`

---

## üöÄ Como Usar

### Iniciar o Sistema
```bash
cd /home/suple/Desktop/suple360v2
./run.sh
```

### Acessar Interface Web
```
http://localhost:5000
```

### Ver Detec√ß√µes Recentes (API)
```
http://localhost:5000/api/detections/recent
```

### Ver Dados do LIDAR (API)
```
http://localhost:5000/api/lidar/latest
```

---

## üîß Manuten√ß√£o

### Onde os dados s√£o salvos?
- **Fotos:** `/home/suple/Desktop/suple360v2/deteccoes/`
- **Banco:** `/home/suple/Desktop/suple360v2/deteccoes/detections.db`

### Limpar hist√≥rico
```
POST http://localhost:5000/api/clear-history
```

### Logs importantes
```python
print("‚úì Buraco detectado!")              # Nova detec√ß√£o
print("[LIDAR] Conectado e operacional")  # LIDAR OK
print("‚úÖ [DB] Detec√ß√£o salva no banco")  # Salvo no DB
```

---

## üìù Resumo

Este sistema √© um **MVP (Minimum Viable Product)** que demonstra:
- ‚úÖ Captura de v√≠deo em tempo real
- ‚úÖ Detec√ß√£o de objetos com IA (YOLO)
- ‚úÖ Fus√£o de sensores (c√¢mera + LIDAR)
- ‚úÖ Persist√™ncia de dados (SQLite)
- ‚úÖ Interface web (Flask)
- ‚úÖ Arquitetura modular e extens√≠vel
- üÜï **An√°lise geom√©trica avan√ßada (OpenCV)**
- üÜï **Tracking inteligente (evita duplicatas)**
- üÜï **Classifica√ß√£o autom√°tica de severidade**

Cada m√≥dulo √© independente e pode ser melhorado/testado separadamente!

---

## üÜï Novidades da Fase 1 (OpenCV + Tracking)

### Dados Coletados por Buraco

**Antes da Fase 1:**
```json
{
  "bbox": [100, 150, 300, 280],
  "confianca": 0.94,
  "distancia_m": 2.3,
  "largura_m": 0.45
}
```
**Total: 7 campos**

---

**Depois da Fase 1:**
```json
{
  "track_id": 1,
  "bbox": [100, 150, 300, 280],
  "confianca": 0.94,
  "distancia_m": 2.3,
  
  "dimensoes_reais": {
    "largura_m": 0.452,
    "altura_m": 0.321,
    "area_m2": 0.1145,
    "perimetro_m": 1.423
  },
  
  "geometria": {
    "aspect_ratio": 1.18,
    "circularidade": 0.82,
    "convexidade": 0.91,
    "orientacao_deg": 23.4
  },
  
  "textura": {
    "intensidade_media": 87.3,
    "desvio_padrao": 24.1,
    "contraste": 0.68
  },
  
  "classificacao": {
    "severidade": "media",
    "prioridade": "media",
    "necessita_reparo": true
  }
}
```
**Total: 21 campos** üéâ

---

### Benef√≠cios Imediatos

#### 1. Evita Duplicatas
```
Antes: 1 buraco = 30 registros no banco ‚ùå
Depois: 1 buraco = 1 registro no banco ‚úÖ
```

#### 2. Dados Mais Ricos
```
Antes: "Buraco detectado com 94% de confian√ßa"
Depois: "Buraco de 0.11 m¬≤, severidade M√âDIA, 
         circularidade 0.82, necessita reparo"
```

#### 3. Prioriza√ß√£o Autom√°tica
```sql
-- Buscar buracos graves que precisam reparo urgente
SELECT * FROM buracos 
WHERE severidade = 'grave' 
  AND prioridade = 'alta'
ORDER BY area_m2 DESC;
```

#### 4. An√°lises Estat√≠sticas
```python
# Tamanho m√©dio dos buracos
SELECT AVG(area_m2) FROM buracos;

# Buracos mais circulares vs irregulares
SELECT severidade, AVG(circularidade) 
FROM buracos 
GROUP BY severidade;
```

---

### Exemplo de Log Detalhado

```
============================================================
‚úì NOVO BURACO DETECTADO! Foto 1
============================================================

Buraco #1 (Track ID: 1):
  √Årea: 0.1145 m¬≤
  Dimens√µes: 0.45m x 0.32m
  Circularidade: 0.82
  Severidade: MEDIA

============================================================
```

---

## üéì Conceitos Aprendidos na Fase 1

### 1. IoU (Intersection over Union)
- M√©trica para comparar sobreposi√ß√£o de bounding boxes
- Usado no tracking para identificar "mesmo buraco"
- Valores de 0 (sem overlap) a 1 (id√™nticos)

### 2. Segmenta√ß√£o de Imagem
- Separar objeto (buraco) do fundo (asfalto)
- Usa threshold adaptativo para lidar com ilumina√ß√£o vari√°vel
- Resulta em contorno preciso do buraco

### 3. An√°lise de Contornos
- `cv2.contourArea()` - √°rea exata ocupada
- `cv2.arcLength()` - per√≠metro do contorno
- `cv2.fitEllipse()` - ajusta elipse ao formato

### 4. Descritores de Forma
- **Circularidade**: O qu√£o pr√≥ximo de um c√≠rculo
- **Convexidade**: O qu√£o irregular √© a borda
- **Aspect Ratio**: Rela√ß√£o entre largura e altura

### 5. Tracking Multi-Objeto
- Manter identidade de objetos entre frames
- Suaviza√ß√£o de posi√ß√£o (evita tremidas)
- Remo√ß√£o autom√°tica de tracks antigos

---

**Criado em:** Janeiro 2026  
**Vers√£o:** 2.1 (Fase 1 - OpenCV + Tracking)  
**Pr√≥xima Fase:** Mapeamento 2D Bird's Eye View


---

## üó∫Ô∏è Fase 2: Mapeamento 2D (Bird's Eye View)

### M√≥dulos Adicionados:
- **mapper.py** - Construtor de mapas 2D top-down
- **map_utils.py** - Convers√µes de coordenadas
- **templates/map.html** - Interface web do mapa

### Funcionalidades:
‚úÖ Mapa 20x20 metros (800x800 pixels)  
‚úÖ Plotagem de buracos com cores por severidade  
‚úÖ Visualiza√ß√£o de LIDAR 360¬∞  
‚úÖ Exporta√ß√£o para PNG  
‚úÖ Interface web com auto-atualiza√ß√£o  

### Acessar:
http://localhost:5000/map

### Para mais detalhes:
Ver arquivo **FASE2_RESUMO.md** para documenta√ß√£o completa.

---

**Vers√£o:** 2.2 (Fase 2 - Mapeamento 2D)  
**√öltima Atualiza√ß√£o:** 06/Janeiro/2026

---

## üî¨ Fase 3: Calibra√ß√£o e Profundidade

### M√≥dulos Adicionados:
- **calibration.py** - Calibra√ß√£o de c√¢mera com padr√£o xadrez
- **depth_estimator.py** - Estimativa de profundidade monocular
- Atualizado **opencv_analyzer.py** - Integra√ß√£o com profundidade
- Atualizado **database.py** - 6 novos campos de profundidade

### Funcionalidades:
‚úÖ Calibra√ß√£o precisa da c√¢mera (matriz intr√≠nseca, distor√ß√£o)  
‚úÖ Estimativa de profundidade usando Shape from Shading  
‚úÖ An√°lise de gradientes, sombras e intensidade  
‚úÖ Classifica√ß√£o: raso (<3cm), m√©dio (3-8cm), profundo (>8cm)  
‚úÖ Novos campos no banco: gradiente, sombra, score, profundidade  
‚úÖ Scripts de calibra√ß√£o e teste  

### Como Calibrar a C√¢mera:

**1. Prepare o padr√£o xadrez:**
```bash
# Imprima um padr√£o xadrez 9x6 (dispon√≠vel online)
# Cada quadrado deve ter 2.5cm x 2.5cm
```

**2. Tire fotos do padr√£o:**
```bash
# Crie pasta para imagens de calibra√ß√£o
mkdir calibracao

# Tire 15-20 fotos do padr√£o em diferentes √¢ngulos
# Certifique-se que o padr√£o est√° completamente vis√≠vel
```

**3. Execute calibra√ß√£o:**
```bash
python3 calibrate_camera.py --images calibracao/*.jpg
```

**4. Resultado:**
```
‚úÖ Calibra√ß√£o conclu√≠da!
üíæ Arquivo salvo: camera_calibration.pkl
üìä Erro de reproje√ß√£o: 0.31 pixels
```

### Como Funciona a Estimativa de Profundidade:

**1. An√°lise de Gradientes (40% do score):**
- Calcula varia√ß√£o de intensidade usando Sobel
- Buracos profundos t√™m bordas mais acentuadas
- Gradiente m√©dio > 35 = profundo

**2. An√°lise de Sombras (30% do score):**
- Mede porcentagem de pixels escuros
- Buracos profundos acumulam sombra interna
- Usa threshold adaptativo (Otsu)

**3. Varia√ß√£o de Intensidade (30% do score):**
- Compara brilho da borda vs centro
- Centro mais escuro indica maior profundidade
- Diferen√ßa > 50 = profundo

**4. Estimativa em Cent√≠metros:**
```python
# Score 0-100 ‚Üí 0.5cm a 10cm
# Ajustado pela dist√¢ncia do LIDAR
profundidade_cm = 0.5 + (score/100) * 9.5
```

### Novos Campos no Banco de Dados:

```sql
-- 6 novos campos na tabela buracos:
gradiente_medio REAL,           -- Intensidade do gradiente (0-255)
intensidade_sombra REAL,        -- % de pixels escuros (0-100)
variacao_intensidade REAL,      -- Diferen√ßa borda-centro (0-255)
profundidade_score REAL,        -- Score combinado (0-100)
profundidade_cm REAL,           -- Profundidade estimada em cm
classificacao_profundidade TEXT -- 'raso', 'medio', 'profundo'
```

### Consultar Dados de Profundidade:

```python
import sqlite3

conn = sqlite3.connect('deteccoes/detections.db')
cursor = conn.cursor()

# Busca buracos profundos
cursor.execute('''
    SELECT 
        area_m2, 
        profundidade_cm, 
        classificacao_profundidade,
        severidade
    FROM buracos
    WHERE classificacao_profundidade = 'profundo'
    ORDER BY profundidade_cm DESC
''')

for row in cursor.fetchall():
    area, prof, classif, sev = row
    print(f"Buraco {sev}: {area:.4f}m¬≤ - {prof:.2f}cm ({classif})")
```

### Scripts Auxiliares:

**1. calibrate_camera.py:**
```bash
# Calibra c√¢mera e salva par√¢metros
python3 calibrate_camera.py --images calibracao/*.jpg
```

**2. test_fase3.py:**
```bash
# Testa todos os componentes da Fase 3
python3 test_fase3.py
```

### Exemplo de Resultado:

```
üìä Buraco detectado:
   √Årea: 0.0823 m¬≤
   Dimens√µes: 0.35m x 0.28m
   
   üî¨ Profundidade:
      Gradiente: 42.15
      Sombra: 68.5%
      Varia√ß√£o: 51.2
      Score: 73.8/100
      Profundidade: 7.5 cm
      Classifica√ß√£o: m√©dio
   
   ‚ö†Ô∏è Severidade: media
   üìç Prioridade: media
```

### Para mais detalhes:
Ver arquivo **FASE3_RESUMO.md** para documenta√ß√£o completa.

---

**Vers√£o:** 2.3 (Fase 3 - Calibra√ß√£o + Profundidade)  
**√öltima Atualiza√ß√£o:** 06/Janeiro/2026

---

## üé® Fase 4: An√°lise Avan√ßada de Textura

### M√≥dulos Adicionados:
- **texture_analyzer.py** - An√°lise GLCM, entropia, FFT (499 linhas)
- **damage_classifier.py** - Classifica√ß√£o de tipo de dano (320 linhas)
- Atualizado **opencv_analyzer.py** - Integra√ß√£o completa
- Atualizado **database.py** - 6 novos campos de textura

### Funcionalidades:
‚úÖ An√°lise GLCM (Gray-Level Co-occurrence Matrix)  
‚úÖ Entropia de Shannon (medida de desordem)  
‚úÖ An√°lise de frequ√™ncias (FFT 2D)  
‚úÖ Histogramas RGB e HSV  
‚úÖ Densidade de bordas (Canny)  
‚úÖ Classifica√ß√£o de textura: lisa, rugosa, irregular, complexa  
‚úÖ Classifica√ß√£o de dano: buraco circular/irregular, rachadura, eros√£o  

### An√°lise GLCM:

A **GLCM** analisa rela√ß√£o espacial entre pixels vizinhos:

```python
# 4 m√©tricas principais:
- Energia: Uniformidade da textura (0-1)
- Homogeneidade: Suavidade da textura (0-1)
- Contraste: Varia√ß√£o local (0-‚àû)
- Correla√ß√£o: Depend√™ncia linear (-1 a 1)
```

**Exemplo de uso:**
```python
from src.texture_analyzer import TextureAnalyzer

analyzer = TextureAnalyzer()
resultado = analyzer.analisar_textura_avancada(roi, contorno)

print(f"Entropia: {resultado['entropia']:.3f}")          # 0-8
print(f"Energia: {resultado['energia']:.3f}")            # 0-1
print(f"Homogeneidade: {resultado['homogeneidade']:.3f}")# 0-1
print(f"Textura: {resultado['textura_dominante']}")      # lisa/rugosa/irregular/complexa
```

### Classifica√ß√£o de Tipo de Dano:

O sistema detecta 4 tipos de danos:

| Tipo | Crit√©rios | Caracter√≠sticas |
|------|-----------|-----------------|
| **Buraco Circular** | Circularidade > 0.65, Convexidade > 0.80 | Compacto, forma regular |
| **Buraco Irregular** | Circularidade < 0.60, Entropia alta | Bordas complexas, irregular |
| **Rachadura** | Aspect ratio > 3.0, Skeleton alongado | Linear, fino, alongado |
| **Eros√£o** | √Årea < 0.08 m¬≤, Bordas difusas | Superficial, disperso |

**Exemplo de uso:**
```python
from src.damage_classifier import DamageClassifier

classifier = DamageClassifier()
resultado = classifier.classificar_dano(roi, contorno, geometria, textura, dimensoes)

print(f"Tipo: {resultado['tipo_dano']}")                    # buraco_circular
print(f"Confian√ßa: {resultado['confianca']:.1f}%")          # 85.3%
print(f"Descri√ß√£o: {resultado['caracteristicas']}")         # "Buraco compacto..."
```

### M√©tricas de Textura:

**1. Entropia de Shannon:**
```python
# Mede complexidade/desordem da textura
Entropia = -Œ£(p * log2(p))

- Baixa (< 4.0): Textura uniforme, lisa
- M√©dia (4.0-6.0): Textura rugosa
- Alta (> 6.0): Textura irregular, complexa
```

**2. An√°lise de Frequ√™ncias (FFT):**
```python
# Detecta padr√µes repetitivos
- Alta frequ√™ncia dominante: Textura detalhada/rugosa
- Baixa frequ√™ncia: Textura lisa/uniforme
- Rugosidade: % de energia em altas frequ√™ncias
```

**3. Densidade de Bordas:**
```python
# Porcentagem de pixels de borda (Canny)
- < 10%: Textura lisa
- 10-30%: Textura rugosa
- > 30%: Textura irregular
```

### Novos Campos no Banco de Dados:

```sql
-- 6 novos campos na tabela buracos:
entropia REAL,                -- Entropia de Shannon (0-8)
energia_glcm REAL,            -- Uniformidade GLCM (0-1)
homogeneidade_glcm REAL,      -- Suavidade GLCM (0-1)
densidade_bordas REAL,        -- % de bordas (0-100)
tipo_dano TEXT,               -- Tipo classificado
tipo_dano_confianca REAL      -- Confian√ßa da classifica√ß√£o (0-100)
```

### Consultar Dados por Tipo de Dano:

```python
import sqlite3

conn = sqlite3.connect('deteccoes/detections.db')
cursor = conn.cursor()

# Busca rachaduras detectadas
cursor.execute('''
    SELECT 
        area_m2,
        aspect_ratio,
        tipo_dano,
        tipo_dano_confianca,
        severidade
    FROM buracos
    WHERE tipo_dano = 'rachadura'
    ORDER BY tipo_dano_confianca DESC
''')

for row in cursor.fetchall():
    area, asp, tipo, conf, sev = row
    print(f"Rachadura {sev}: {area:.4f}m¬≤ (asp={asp:.2f}) - {conf:.1f}% confian√ßa")
```

### Exemplo de Resultado Completo:

```
üìä Buraco detectado:
   Dimens√µes: 0.35m x 0.28m (0.0823 m¬≤)
   
   üé® Textura B√°sica:
      Intensidade: 87.3
      Desvio padr√£o: 24.1
      Contraste: 0.68
   
   üî¨ Textura Avan√ßada (Fase 4):
      Entropia: 5.23
      Energia: 0.31
      Homogeneidade: 0.58
      Contraste GLCM: 142.5
      Densidade bordas: 28.3%
      Textura dominante: rugosa
   
   üîç Tipo de Dano (Fase 4):
      Tipo: buraco_irregular
      Confian√ßa: 78.5%
      Tipo secund√°rio: None
      Descri√ß√£o: Buraco irregular (circ=0.42), bordas complexas
   
   üî¨ Profundidade:
      Profundidade: 7.5 cm
      Classifica√ß√£o: m√©dio
   
   ‚ö†Ô∏è Severidade: media
   üìç Prioridade: media
```

### Scripts de Teste:

```bash
# Testa an√°lise de textura avan√ßada
python3 test_fase4.py
```

**Sa√≠da esperada:**
```
‚úÖ TESTE 1: An√°lise de Textura Avan√ßada
   Entropia: 0.926
   Homogeneidade: 0.966
   Textura dominante: lisa

‚úÖ TESTE 2: Classifica√ß√£o de Tipo de Dano
   CIRCULAR: buraco_circular (100.0%)
   IRREGULAR: buraco_irregular (80.0%)
   RACHADURA: rachadura (90.0%)
   EROSAO: erosao (70.0%)

‚úÖ TESTE 3: Integra√ß√£o Completa
   Todos os m√≥dulos funcionando ‚úì
```

### Para mais detalhes:
Ver arquivo **FASE4_RESUMO.md** para documenta√ß√£o completa.

---

**Vers√£o:** 2.4 (Fase 4 - An√°lise Avan√ßada de Textura)  
**√öltima Atualiza√ß√£o:** 06/Janeiro/2026

---

## ‚ö° Fase 5: Otimiza√ß√£o de Performance

### M√≥dulos Adicionados:
- **roi_detector.py** - Detec√ß√£o de ROI (Region of Interest) (165 linhas)
- **motion_detector.py** - Detec√ß√£o de movimento (175 linhas)
- **performance_optimizer.py** - Multi-threading e pipeline otimizado (230 linhas)

### Funcionalidades:
‚úÖ ROI Detection: 4 modos (full, bottom_half, bottom_two_thirds, adaptive)  
‚úÖ Motion Detection: 2 m√©todos (frame_diff, mog2)  
‚úÖ Multi-threading: Workers paralelos com fila ass√≠ncrona  
‚úÖ Adaptive Frame Skipping: Mant√©m FPS alvo  
‚úÖ M√©tricas em tempo real: FPS, skip rate, processing time  

### Speedup Alcan√ßado:

| Otimiza√ß√£o | Speedup | Descri√ß√£o |
|------------|---------|-----------|
| Baseline | 1.0x | Sem otimiza√ß√£o |
| ROI Detection | 2.0x | Processa s√≥ metade inferior |
| Motion Detection | **18x** | Pula frames est√°ticos |
| **Combinado** | **20x** | ROI + Motion juntos |

### 1. ROI Detection (Region of Interest):

**Problema:** Processar frame completo desperdi√ßa recursos (buracos n√£o aparecem no c√©u).

**Solu√ß√£o:** Processar apenas regi√£o relevante.

**Modos dispon√≠veis:**

```python
from src.roi_detector import ROIDetector

# Modo 1: Metade inferior (50% redu√ß√£o, 2x speedup)
detector = ROIDetector(roi_mode='bottom_half')
roi, bbox = detector.get_roi(frame)

# Modo 2: 2/3 inferiores (33% redu√ß√£o, 1.5x speedup)
detector = ROIDetector(roi_mode='bottom_two_thirds')

# Modo 3: Adaptativo (detecta asfalto automaticamente)
detector = ROIDetector(roi_mode='adaptive')

# Modo 4: Completo (sem otimiza√ß√£o)
detector = ROIDetector(roi_mode='full')
```

**Uso com detector:**
```python
# Extrai ROI
roi, roi_bbox = detector.get_roi(frame)

# Detecta buracos na ROI
boxes = yolo_detector.detect(roi)

# Ajusta coordenadas para frame original
for box in boxes:
    adjusted_box = detector.adjust_bbox_to_original(box, roi_bbox)
```

### 2. Motion Detection:

**Problema:** Processar frames id√™nticos (ve√≠culo parado) desperdi√ßa recursos.

**Solu√ß√£o:** Detectar movimento e pular frames est√°ticos.

**M√©todos dispon√≠veis:**

```python
from src.motion_detector import MotionDetector

# M√©todo 1: Frame Differencing (r√°pido)
detector = MotionDetector(method='frame_diff', threshold=0.02)

# M√©todo 2: Background Subtraction MOG2 (preciso)
detector = MotionDetector(method='mog2', threshold=0.02)

# Verifica movimento
has_motion, score = detector.has_motion(frame)

if has_motion:
    # Processa frame
    result = process_frame(frame)
else:
    # Pula frame (economiza recursos)
    pass
```

**Estat√≠sticas:**
```python
stats = detector.get_stats()
print(f"Taxa de pulo: {stats['skip_rate']:.1f}%")
print(f"Speedup estimado: {stats['estimated_speedup']:.2f}x")
```

### 3. Multi-threading:

**Problema:** Processamento sequencial subutiliza CPU multi-core.

**Solu√ß√£o:** Pipeline com workers paralelos.

```python
from src.performance_optimizer import PerformanceOptimizer

def process_function(frame):
    # Sua fun√ß√£o de processamento
    return yolo.detect(frame)

# Cria otimizador com 2 workers
optimizer = PerformanceOptimizer(
    process_func=process_function,
    max_queue_size=5,
    num_workers=2
)

optimizer.start()

# Submete frames
for i, frame in enumerate(frames):
    optimizer.submit_frame(frame, i)

# Pega resultados
result = optimizer.get_result(timeout=0.1)
if result:
    frame_id, detection, processing_time = result

optimizer.stop()
```

### 4. Adaptive Frame Skipping:

**Problema:** C√¢mera captura 30 FPS mas processamento √© 10 FPS.

**Solu√ß√£o:** Pular frames adaptativamente para manter FPS alvo.

```python
from src.performance_optimizer import AdaptiveFrameSkipper

# Mant√©m 10 FPS
skipper = AdaptiveFrameSkipper(target_fps=10)

while True:
    frame = camera.read()
    
    if skipper.should_process():
        # Processa frame
        result = process(frame)
    else:
        # Pula frame
        continue
```

### Benchmark Completo:

```
üìä RESULTADOS:
  Sem otimiza√ß√£o:     1.51s  (33 FPS)   [baseline]
  Com ROI:            1.51s  (33 FPS)   [1.0x]
  Com Motion:         0.08s  (606 FPS)  [18x] ‚ö°
  Com TUDO:           0.07s  (681 FPS)  [20x] üöÄ
```

**Interpreta√ß√£o:**
- ROI sozinho: n√£o melhora muito (frames j√° tinham movimento)
- Motion Detection: **18x mais r√°pido** (pula 98% dos frames est√°ticos)
- Combinado: **20x mais r√°pido** (economia m√°xima)

### Configura√ß√£o Recomendada:

**Para ve√≠culo em movimento:**
```python
roi = ROIDetector(roi_mode='bottom_half')          # 2x speedup
motion = MotionDetector(method='frame_diff', threshold=0.02)  # 18x speedup
```

**Para ve√≠culo frequentemente parado:**
```python
roi = ROIDetector(roi_mode='bottom_two_thirds')    # 1.5x speedup
motion = MotionDetector(method='mog2', threshold=0.01)  # Mais sens√≠vel
```

### M√©tricas em Tempo Real:

```python
# ROI Detector
print(f"Speedup estimado: {roi.estimate_speedup():.1f}x")

# Motion Detector
stats = motion.get_stats()
print(f"Taxa de pulo: {stats['skip_rate']:.1f}%")
print(f"Speedup: {stats['estimated_speedup']:.2f}x")

# Performance Optimizer
metrics = optimizer.get_metrics()
print(f"FPS: {metrics['fps']:.1f}")
print(f"Tempo m√©dio: {metrics['avg_processing_time_ms']:.1f}ms")
print(f"Fila: {metrics['queue_size']}")
```

### Scripts de Teste:

```bash
# Testa otimiza√ß√µes e roda benchmark
python3 test_fase5.py
```

**Sa√≠da esperada:**
```
‚úÖ TESTE 1: ROI Detector
   bottom_half: 50% redu√ß√£o, 2.0x speedup

‚úÖ TESTE 2: Motion Detector
   Taxa de pulo: 98.0%
   Speedup: 50.00x (frames est√°ticos)

‚úÖ TESTE 3: Multi-threading
   FPS: 1.0, Tempo m√©dio: 30.1ms

‚úÖ TESTE 4: Adaptive Frame Skipper
   5 FPS: 83% pulo
   10 FPS: 66% pulo
   15 FPS: 50% pulo

üìä BENCHMARK:
   Speedup combinado: 20.53x üöÄ
```

### Quando Usar Cada Otimiza√ß√£o:

| Cen√°rio | ROI | Motion | Multi-thread |
|---------|-----|--------|--------------|
| Ve√≠culo em movimento constante | ‚úÖ | ‚ùå | ‚úÖ |
| Ve√≠culo parado frequentemente | ‚úÖ | ‚úÖ‚úÖ | ‚úÖ |
| Processamento pesado (YOLO + an√°lise completa) | ‚úÖ | ‚úÖ | ‚úÖ‚úÖ |
| Hardware limitado (Raspberry Pi) | ‚úÖ‚úÖ | ‚úÖ | ‚ùå |

### Para mais detalhes:
Ver arquivo **FASE5_RESUMO.md** para documenta√ß√£o completa.

---

**Vers√£o:** 2.5 (Fase 5 - Otimiza√ß√£o de Performance)  
**√öltima Atualiza√ß√£o:** 06/Janeiro/2026

---

## üìê Fase 6: Sistema de Calibra√ß√£o Completo

### M√≥dulos Adicionados:
- **pattern_generator.py** - Gera√ß√£o de padr√µes de calibra√ß√£o (PDF) (310 linhas)
- **templates/calibracao.html** - Interface para gerar PDFs (350 linhas)
- **templates/calibracao_live.html** - Calibra√ß√£o em tempo real (600 linhas)
- Atualizado **api.py** - 8 novas rotas de calibra√ß√£o

### Funcionalidades:
‚úÖ Gera√ß√£o de padr√µes xadrez 9√ó6 em PDF (25mm por quadrado)  
‚úÖ Gera√ß√£o de markers ArUco em PDF (DICT_6X6_250, 100mm)  
‚úÖ Interface web para download de PDFs  
‚úÖ Calibra√ß√£o em tempo real com stream de v√≠deo  
‚úÖ Detec√ß√£o autom√°tica de padr√µes (xadrez e ArUco)  
‚úÖ Captura de m√∫ltiplas fotos (m√≠n. 10, rec. 15-20)  
‚úÖ C√°lculo de matriz intr√≠nseca e coeficientes de distor√ß√£o  
‚úÖ Salvamento de calibra√ß√µes (.npz)  
‚úÖ Visualiza√ß√£o de calibra√ß√µes salvas  

---

### 1. O que √© Calibra√ß√£o de C√¢mera?

**Calibra√ß√£o** √© o processo de medir os **par√¢metros internos** da c√¢mera para:

**a) Corrigir distor√ß√µes da lente:**
```
Antes:                 Depois:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤  ‚îÇ          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ (  ‚ñ°  ) ‚îÇ    ‚Üí     ‚îÇ  ‚îÇ  ‚ñ°  ‚îÇ  ‚îÇ  (linhas retas)
‚îÇ  ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚ï±  ‚îÇ          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  (distor√ß√£o)          (corrigido)
```

**b) Medir dimens√µes reais com precis√£o:**
```
Sem calibra√ß√£o:        Com calibra√ß√£o:
Buraco = "203 pixels"  Buraco = 0.452 m
(n√£o sabe metros)      (medida exata!)
```

---

### 2. Matriz Intr√≠nseca da C√¢mera

A calibra√ß√£o calcula a **matriz intr√≠nseca** (3√ó3):

```python
K = [
    [fx,  0, cx],
    [ 0, fy, cy],
    [ 0,  0,  1]
]
```

**Par√¢metros:**
- **fx, fy**: Dist√¢ncia focal (em pixels)
  - Controla o "zoom" da c√¢mera
  - T√≠pico: 500-1500 px para c√¢mera Raspberry Pi
  
- **cx, cy**: Centro √≥ptico (coordenadas do pixel central)
  - Idealmente no centro da imagem
  - Exemplo: (640, 360) para resolu√ß√£o 1280√ó720

**Coeficientes de Distor√ß√£o:**
```python
dist = [k1, k2, p1, p2, k3]
```
- **k1, k2, k3**: Distor√ß√£o radial (efeito "barril" ou "almofada")
- **p1, p2**: Distor√ß√£o tangencial (desalinhamento da lente)

**Onde √© usado:**
- Convers√£o pixel ‚Üí metro (estimativa de tamanho real)
- Corre√ß√£o de distor√ß√£o de imagem
- Mapeamento 3D preciso

---

### 3. Como Funciona a Calibra√ß√£o

#### **Etapa 1: Gera√ß√£o de Padr√µes**

**Acesse:** `http://localhost:5000/calibracao`

**Padr√µes dispon√≠veis:**

**a) Xadrez 9√ó6 (Recomendado para iniciantes):**
- 9 cantos internos na horizontal
- 6 cantos internos na vertical
- 54 cantos totais para detec√ß√£o
- Quadrados de 25mm √ó 25mm

**b) ArUco Markers (Recomendado para precis√£o):**
- 10 markers √∫nicos (IDs 0-9)
- Dicion√°rio: DICT_6X6_250
- Tamanho: 100mm √ó 100mm
- Precis√£o 4-6x melhor que xadrez

**Como gerar:**
```python
# Backend (pattern_generator.py)
from pattern_generator import CalibrationPatternGenerator

generator = CalibrationPatternGenerator()

# Gera xadrez
generator.gerar_padrao_xadrez(
    pattern_size=(9, 6),      # 9√ó6 cantos
    square_size_mm=25,        # 25mm por quadrado
    output_path='xadrez.pdf'
)

# Gera ArUco
generator.gerar_aruco_markers(
    num_markers=10,           # 10 markers
    marker_size_mm=100,       # 100mm de tamanho
    output_path='aruco.pdf'
)
```

**Clique nos bot√µes da interface:**
- üì• Baixar Padr√£o Xadrez
- üì• Baixar Markers ArUco

---

#### **Etapa 2: Impress√£o e Prepara√ß√£o**

**Instru√ß√µes cr√≠ticas:**

1. **Imprima em A4** sem escalar (100% do tamanho)
2. **Cole em superf√≠cie r√≠gida** (papel√£o, placa de isopor)
3. **Certifique-se que est√° plano** (sem dobras ou curvas)
4. **Me√ßa o tamanho real** com r√©gua:
   - Xadrez: cada quadrado deve ter ~25mm
   - ArUco: cada marker deve ter ~100mm

**Por que a precis√£o importa?**
```
Erro de 1mm na impress√£o = erro de 5-10cm na medi√ß√£o final!
```

---

#### **Etapa 3: Calibra√ß√£o em Tempo Real**

**Acesse:** `http://localhost:5000/calibracao_live`

**Interface:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìπ Visualiza√ß√£o da C√¢mera                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   [Stream com overlay de detec√ß√£o]    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚úì Padr√£o detectado! | 54 cantos     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚öôÔ∏è Configura√ß√µes                            ‚îÇ
‚îÇ  Tipo: [Xadrez 9√ó6 ‚ñº]                      ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  üìä Estat√≠sticas                             ‚îÇ
‚îÇ  Fotos: 12     Taxa: 85%                    ‚îÇ
‚îÇ  Qualidade: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 80%                  ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  üì∏ [Capturar Frame]  üéØ [Calibrar]         ‚îÇ
‚îÇ  üîÑ [Resetar]                               ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  üìä Resultados:                              ‚îÇ
‚îÇ  Erro: 0.42 px | Focal: 1234.5 px          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Elementos da tela:**

**1. Taxa de Detec√ß√£o (0-100%):**
```python
# Mede: quantos frames detectam o padr√£o
taxa = (frames_detectados / frames_totais) √ó 100%

# Interpreta√ß√£o:
> 80% = √ìtimo! Padr√£o bem posicionado ‚úÖ
50-80% = Razo√°vel, ajuste √¢ngulo ‚ö†Ô∏è
< 50% = Ruim, padr√£o n√£o est√° vis√≠vel ‚ùå
```

**2. Qualidade da Imagem (barra colorida):**
```python
# Xadrez: quantos cantos foram detectados
qualidade = (cantos_detectados / 54) √ó 100%

# ArUco: quantos markers foram detectados  
qualidade = (markers_detectados / 10) √ó 100%

# Cores:
üü¢ Verde (70-100%): Capture agora!
üü° Amarelo (40-70%): Ajuste posi√ß√£o
üî¥ Vermelho (0-40%): Padr√£o parcial
```

**3. Bot√£o "Capturar Frame":**
```python
# O que faz:
1. Verifica se padr√£o est√° detectado
2. Salva frame + coordenadas dos cantos/markers
3. Incrementa contador de fotos
4. Mostra alerta de sucesso

# Quando usar:
- Status: "Padr√£o detectado!" (luz verde)
- Qualidade: > 70% (barra verde)
- √Çngulo diferente das fotos anteriores
```

**4. Bot√£o "Calibrar" (m√≠n. 10 fotos):**
```python
# Requisitos:
- M√≠nimo: 10 fotos capturadas
- Recomendado: 15-20 fotos
- Variedade de √¢ngulos

# O que faz:
1. Executa cv2.calibrateCamera() ou cv2.aruco.calibrateCameraAruco()
2. Calcula matriz intr√≠nseca K
3. Calcula coeficientes de distor√ß√£o
4. Calcula erro de reproje√ß√£o
5. Salva em .npz

# Resultado:
{
    "reprojection_error": 0.42,  # px (quanto menor melhor)
    "focal_x": 1234.5,           # px
    "focal_y": 1236.8,           # px
    "center_x": 640.2,           # px
    "center_y": 359.8,           # px
    "calibration_file": "calibracao_chessboard.npz"
}
```

---

#### **Etapa 4: Como Capturar Fotos Corretamente**

**Objetivo:** Cobrir diferentes √¢ngulos e dist√¢ncias para calibra√ß√£o robusta.

**Estrat√©gia recomendada (15-20 fotos):**

```
Vista Superior:

Posi√ß√£o 1-4: Centro em diferentes dist√¢ncias
   üéØ        üéØ      üéØ    üéØ
  perto    m√©dio   m√©dio  longe

Posi√ß√£o 5-8: √Çngulos inclinados
   üéØ        üéØ      üéØ    üéØ
  ‚Üó30¬∞     ‚Üñ30¬∞    ‚Üò30¬∞  ‚Üô30¬∞

Posi√ß√£o 9-12: Cantos da imagem
   üéØ                    üéØ
  canto               canto
  sup-esq            sup-dir

   üéØ                    üéØ
  canto               canto
  inf-esq            inf-dir

Posi√ß√£o 13-16: Rota√ß√£o do padr√£o
   üìÑ        üìÑ      üìÑ    üìÑ
  0¬∞       45¬∞     90¬∞   135¬∞

Posi√ß√£o 17-20: Varia√ß√µes de ilumina√ß√£o
   üîÜ luz   ‚òÄÔ∏è sol  üåô sombra  üí° lateral
```

**Dicas:**
- ‚úÖ Sempre mantenha o padr√£o **completamente vis√≠vel**
- ‚úÖ Varie **√¢ngulo, dist√¢ncia e rota√ß√£o**
- ‚úÖ Capture em **diferentes ilumina√ß√µes**
- ‚ùå N√£o capture fotos muito similares (desperd√≠cio)
- ‚ùå N√£o cubra parte do padr√£o com a m√£o
- ‚ùå N√£o capture com padr√£o dobrado/amassado

---

#### **Etapa 5: Executar Calibra√ß√£o**

**Backend (api.py):**

```python
@app.route('/api/calibracao_executar', methods=['POST'])
def calibracao_executar():
    # 1. Verifica m√≠nimo de 10 fotos
    if len(calibration_images) < 10:
        return error("M√≠nimo 10 fotos")
    
    # 2. Monta pontos 3D (mundo real)
    objpoints = []  # Coordenadas 3D reais (0,0,0), (25mm,0,0), ...
    imgpoints = []  # Coordenadas 2D na imagem (pixels)
    
    for img_data in calibration_images:
        objpoints.append(objp)          # Padr√£o conhecido
        imgpoints.append(img_data['corners'])  # Cantos detectados
    
    # 3. Calibra c√¢mera
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
        objpoints, imgpoints, (w, h), None, None
    )
    
    # 4. Calcula erro de reproje√ß√£o
    mean_error = 0
    for i in range(len(objpoints)):
        # Projeta pontos 3D de volta para 2D
        imgpoints2, _ = cv2.projectPoints(
            objpoints[i], rvecs[i], tvecs[i], mtx, dist
        )
        # Calcula diferen√ßa entre real e projetado
        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)
        mean_error += error
    mean_error /= len(objpoints)
    
    # 5. Salva resultado
    np.savez(
        'calibracao_chessboard.npz',
        camera_matrix=mtx,
        dist_coeffs=dist,
        pattern_type='chessboard',
        num_images=len(calibration_images),
        timestamp=int(time.time())
    )
    
    return jsonify({
        "reprojection_error": mean_error,
        "focal_x": float(mtx[0, 0]),
        "focal_y": float(mtx[1, 1]),
        ...
    })
```

---

#### **Etapa 6: Interpreta√ß√£o de Resultados**

**Erro de Reproje√ß√£o:**

```python
# Quanto menor, melhor a calibra√ß√£o
< 0.5 px   = Excelente! ‚úÖ‚úÖ‚úÖ
0.5-1.0 px = Bom ‚úÖ‚úÖ
1.0-2.0 px = Aceit√°vel ‚úÖ
> 2.0 px   = Ruim, recalibre ‚ùå
```

**O que significa?**
- Erro de 0.5 px = ao reprojetar pontos 3D, eles ficam 0.5 pixels distantes do esperado
- Erro alto = calibra√ß√£o imprecisa, medi√ß√µes erradas

**Como melhorar:**
1. Tire mais fotos (20-25)
2. Cubra mais √¢ngulos diferentes
3. Use padr√£o ArUco (mais preciso)
4. Certifique-se que padr√£o est√° plano
5. Use boa ilumina√ß√£o (sem sombras)

**Par√¢metros da C√¢mera:**

```python
# Exemplo de resultado:
Focal X: 1234.5 px
Focal Y: 1236.8 px
Centro: (640.2, 359.8)

# Valida√ß√µes:
‚úÖ fx ‚âà fy (diferen√ßa < 5%) = lente OK
‚ùå fx muito diferente de fy = lente defeituosa
‚úÖ centro pr√≥ximo de (640, 360) para 1280√ó720 = OK
‚ùå centro muito deslocado = c√¢mera desalinhada
```

---

### 4. Onde as Calibra√ß√µes s√£o Salvas?

**Localiza√ß√£o:**
```bash
/home/suple/Desktop/suple360v2/calibracao_chessboard.npz
/home/suple/Desktop/suple360v2/calibracao_aruco.npz
```

**Conte√∫do do arquivo .npz:**

```python
import numpy as np

# Carregar calibra√ß√£o
data = np.load('calibracao_chessboard.npz')

# Acessar par√¢metros
camera_matrix = data['camera_matrix']  # Matriz K 3√ó3
dist_coeffs = data['dist_coeffs']      # [k1, k2, p1, p2, k3]
pattern_type = data['pattern_type']    # 'chessboard' ou 'aruco'
num_images = data['num_images']        # Quantas fotos usadas
timestamp = data['timestamp']          # Unix timestamp

print(f"C√¢mera calibrada com {num_images} fotos")
print(f"Matriz intr√≠nseca:\n{camera_matrix}")
print(f"Distor√ß√£o: {dist_coeffs}")
```

---

### 5. Visualiza√ß√£o de Calibra√ß√µes Salvas

**Interface:** Na parte inferior de `/calibracao_live`

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üíæ Calibra√ß√µes Salvas                       ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ üìê Xadrez 9√ó6                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Erro: 0.42 px    Fotos: 15          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Focal X: 1234.5  Focal Y: 1236.8    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Centro: (640, 360)                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Data: 06/01/2026 14:32               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ [üóëÔ∏è Deletar]                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ üìê ArUco Markers                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Erro: 0.28 px    Fotos: 18          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Focal X: 1235.2  Focal Y: 1237.1    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Centro: (641, 359)                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Data: 06/01/2026 15:45               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ [üóëÔ∏è Deletar]                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Funcionalidades:**
- **Listar:** GET `/api/calibracao_listar`
  - Varre arquivos `.npz` no diret√≥rio
  - L√™ metadados de cada calibra√ß√£o
  - Ordena por data (mais recente primeiro)

- **Deletar:** POST `/api/calibracao_deletar`
  - Remove arquivo `.npz` do disco
  - Atualiza lista automaticamente

**Backend:**

```python
@app.route('/api/calibracao_listar')
def calibracao_listar():
    calibrations = []
    
    for filepath in glob.glob('calibracao_*.npz'):
        data = np.load(filepath)
        calibrations.append({
            'filename': os.path.basename(filepath),
            'pattern_type': str(data['pattern_type']),
            'num_images': int(data['num_images']),
            'focal_x': float(data['camera_matrix'][0, 0]),
            'focal_y': float(data['camera_matrix'][1, 1]),
            'center_x': float(data['camera_matrix'][0, 2]),
            'center_y': float(data['camera_matrix'][1, 2]),
            'timestamp': int(data['timestamp'])
        })
    
    # Ordena por timestamp
    calibrations.sort(key=lambda x: x['timestamp'], reverse=True)
    
    return jsonify({"calibrations": calibrations})
```

---

### 6. Como Usar a Calibra√ß√£o no Sistema

**Carregar calibra√ß√£o salva:**

```python
import numpy as np
import cv2

# Carrega par√¢metros
data = np.load('calibracao_chessboard.npz')
camera_matrix = data['camera_matrix']
dist_coeffs = data['dist_coeffs']

# Corrige distor√ß√£o de imagem
frame_undistorted = cv2.undistort(
    frame, camera_matrix, dist_coeffs
)

# Converte pixel ‚Üí metro (usando dist√¢ncia do LIDAR)
def pixel_to_meter(bbox_width_px, distance_m):
    # FOV horizontal da c√¢mera
    fov_rad = 2 * np.arctan(image_width / (2 * camera_matrix[0, 0]))
    
    # Largura real do campo de vis√£o na dist√¢ncia D
    real_fov_width = 2 * distance_m * np.tan(fov_rad / 2)
    
    # Fator de convers√£o
    meters_per_pixel = real_fov_width / image_width
    
    # Largura real do buraco
    real_width_m = bbox_width_px * meters_per_pixel
    
    return real_width_m
```

**Integra√ß√£o com detector:**

```python
# Em opencv_analyzer.py
class OpenCVAnalyzer:
    def __init__(self, calibration_file=None):
        if calibration_file:
            data = np.load(calibration_file)
            self.camera_matrix = data['camera_matrix']
            self.dist_coeffs = data['dist_coeffs']
        else:
            self.camera_matrix = None
            self.dist_coeffs = None
    
    def analisar_buraco(self, frame, bbox, distancia_m):
        # Se calibrado, corrige distor√ß√£o
        if self.camera_matrix is not None:
            frame = cv2.undistort(frame, self.camera_matrix, self.dist_coeffs)
        
        # Usa calibra√ß√£o para medir com mais precis√£o
        if self.camera_matrix is not None and distancia_m:
            largura_real = self._pixel_to_meter_calibrated(
                bbox_width, distancia_m
            )
        else:
            largura_real = self._pixel_to_meter_estimated(
                bbox_width, distancia_m
            )
        
        return {
            'dimensoes_reais': {
                'largura_m': largura_real,
                ...
            }
        }
```

---

### 7. Compara√ß√£o: Xadrez vs ArUco

| Aspecto | Xadrez 9√ó6 | ArUco Markers |
|---------|-----------|---------------|
| **Precis√£o** | ¬±3-8 cm | ¬±1-3 cm (4-6x melhor) |
| **Facilidade** | ‚úÖ‚úÖ‚úÖ F√°cil | ‚úÖ‚úÖ M√©dio |
| **Custo** | R$ 0 (imprimir) | R$ 0 (imprimir) |
| **Robustez** | ‚ö†Ô∏è Sens√≠vel √† ilumina√ß√£o | ‚úÖ Robusto |
| **Uso em campo** | ‚ùå S√≥ para calibra√ß√£o | ‚úÖ Calibra√ß√£o + medi√ß√£o em tempo real |
| **Recomendado para** | Calibra√ß√£o b√°sica | Calibra√ß√£o precisa + sistema de medi√ß√£o |

**Quando usar Xadrez:**
- Primeira calibra√ß√£o (aprendizado)
- Ambiente controlado (boa ilumina√ß√£o)
- Precis√£o de ¬±5cm √© aceit√°vel

**Quando usar ArUco:**
- Precis√£o cr√≠tica (¬±1-3cm)
- Uso em campo (medi√ß√£o cont√≠nua)
- Ilumina√ß√£o vari√°vel
- Sistema profissional

---

### 8. Rotas da API de Calibra√ß√£o

```python
# Gera√ß√£o de PDFs
GET  /calibracao                  # P√°gina de download
GET  /api/gerar_padrao_xadrez     # Baixa PDF xadrez
GET  /api/gerar_aruco_markers     # Baixa PDF ArUco

# Calibra√ß√£o em tempo real
GET  /calibracao_live             # P√°gina de calibra√ß√£o
GET  /api/calibracao_stream       # Stream MJPEG com detec√ß√£o
GET  /api/calibracao_status       # Status atual {pattern_detected, quality}
POST /api/calibracao_capturar     # Captura 1 foto
POST /api/calibracao_executar     # Executa calibra√ß√£o
POST /api/calibracao_resetar      # Limpa fotos capturadas

# Gest√£o de calibra√ß√µes
GET  /api/calibracao_listar       # Lista calibra√ß√µes salvas
POST /api/calibracao_deletar      # Deleta calibra√ß√£o
```

---

### 9. Fluxo Completo de Uso

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 1: Prepara√ß√£o                         ‚îÇ
‚îÇ 1. Acessa /calibracao                       ‚îÇ
‚îÇ 2. Baixa PDF do padr√£o (xadrez ou ArUco)    ‚îÇ
‚îÇ 3. Imprime em A4 (100% de escala)           ‚îÇ
‚îÇ 4. Cola em superf√≠cie r√≠gida e plana        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 2: Captura de Fotos                   ‚îÇ
‚îÇ 1. Acessa /calibracao_live                  ‚îÇ
‚îÇ 2. Seleciona tipo de padr√£o                 ‚îÇ
‚îÇ 3. Segura padr√£o na frente da c√¢mera        ‚îÇ
‚îÇ 4. Aguarda "Padr√£o detectado!" (luz verde)  ‚îÇ
‚îÇ 5. Clica "Capturar Frame" (foto 1)          ‚îÇ
‚îÇ 6. Muda √¢ngulo/dist√¢ncia                    ‚îÇ
‚îÇ 7. Repete at√© 15-20 fotos                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 3: Calibra√ß√£o                         ‚îÇ
‚îÇ 1. Verifica: "12 fotos capturadas"          ‚îÇ
‚îÇ 2. Clica "Calibrar"                         ‚îÇ
‚îÇ 3. Aguarda processamento (~5-10s)           ‚îÇ
‚îÇ 4. Verifica erro < 1.0 px ‚úÖ               ‚îÇ
‚îÇ 5. Calibra√ß√£o salva em .npz                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 4: Uso no Sistema                     ‚îÇ
‚îÇ 1. Sistema carrega calibracao_*.npz         ‚îÇ
‚îÇ 2. Corrige distor√ß√£o de frames              ‚îÇ
‚îÇ 3. Mede buracos com precis√£o ¬±1-3cm         ‚îÇ
‚îÇ 4. Salva medidas no banco de dados          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 10. Resolu√ß√£o de Problemas

**Problema:** Padr√£o n√£o √© detectado (taxa 0%)

**Solu√ß√µes:**
- ‚úÖ Certifique que padr√£o est√° completamente vis√≠vel
- ‚úÖ Melhore ilumina√ß√£o (sem sombras)
- ‚úÖ Aproxime o padr√£o da c√¢mera
- ‚úÖ Verifique se imprimiu na escala correta

---

**Problema:** Qualidade sempre baixa (< 40%)

**Solu√ß√µes:**
- ‚úÖ Limpe a lente da c√¢mera
- ‚úÖ Cole o padr√£o em superf√≠cie mais r√≠gida
- ‚úÖ Evite reflexos (flash, luz direta)
- ‚úÖ Use padr√£o ArUco (mais robusto)

---

**Problema:** Erro de reproje√ß√£o alto (> 2.0 px)

**Solu√ß√µes:**
- ‚úÖ Tire mais fotos (20-25)
- ‚úÖ Cubra mais √¢ngulos diferentes
- ‚úÖ Certifique que padr√£o est√° perfeitamente plano
- ‚úÖ Verifique medida real do padr√£o impresso
- ‚úÖ Resete e comece novamente

---

**Problema:** Bot√£o "Calibrar" desabilitado

**Causa:** Menos de 10 fotos capturadas

**Solu√ß√£o:** Capture mais fotos at√© ter 10+

---

### 11. Atalhos no Sistema

**Na p√°gina inicial (`/`):**

```html
üó∫Ô∏è [Mapa 2D]           ‚Üí /map
üìê [Gerar Padr√µes]      ‚Üí /calibracao
üéØ [Calibra√ß√£o Live]    ‚Üí /calibracao_live
```

Todos abrem em nova aba para facilitar navega√ß√£o.

---

### 12. Arquivos Criados

```
src/
‚îú‚îÄ‚îÄ pattern_generator.py          # Gera PDFs de calibra√ß√£o
‚îú‚îÄ‚îÄ api.py                         # +8 rotas de calibra√ß√£o
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ calibracao.html            # Download de PDFs
    ‚îî‚îÄ‚îÄ calibracao_live.html       # Interface de calibra√ß√£o

deteccoes/
‚îú‚îÄ‚îÄ padrao_xadrez.pdf              # PDF gerado
‚îî‚îÄ‚îÄ aruco_markers.pdf              # PDF gerado

/
‚îú‚îÄ‚îÄ calibracao_chessboard.npz      # Calibra√ß√£o salva (xadrez)
‚îî‚îÄ‚îÄ calibracao_aruco.npz           # Calibra√ß√£o salva (ArUco)
```

---

### 13. Tecnologias Utilizadas

**Backend:**
- **ReportLab**: Gera√ß√£o de PDFs
- **OpenCV**: Detec√ß√£o de padr√µes (cv2.findChessboardCorners, cv2.aruco)
- **NumPy**: Salvamento de calibra√ß√µes (.npz)
- **Flask**: API REST

**Frontend:**
- **HTML5 + CSS3**: Interface responsiva
- **JavaScript (Vanilla)**: Interatividade
- **MJPEG Streaming**: Stream de v√≠deo em tempo real

**Algoritmos:**
- **cv2.calibrateCamera()**: Calibra√ß√£o com xadrez
- **cv2.aruco.calibrateCameraAruco()**: Calibra√ß√£o com ArUco
- **cv2.projectPoints()**: C√°lculo de erro de reproje√ß√£o

---

### 14. Pr√≥ximos Passos

**Integra√ß√£o futura:**
1. Carregar calibra√ß√£o automaticamente ao iniciar sistema
2. Bot√£o "Aplicar calibra√ß√£o" no detector
3. M√©tricas de precis√£o em tempo real
4. Recalibra√ß√£o autom√°tica peri√≥dica
5. Detec√ß√£o de ArUco em campo para medi√ß√£o cont√≠nua

---

**Vers√£o:** 2.6 (Fase 6 - Sistema de Calibra√ß√£o Completo)  
**√öltima Atualiza√ß√£o:** 06/Janeiro/2026  
**Autor:** Sistema Suple360 v2

